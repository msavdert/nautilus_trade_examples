# üìä PostgreSQL Historical Data Sorgularƒ±

## Nautilus Trader Historical Data Rehberi

Bu dok√ºmantasyon, Nautilus Trader PostgreSQL veritabanƒ±ndaki historical datalarƒ± nasƒ±l sorgulayacaƒüƒ±nƒ±zƒ± g√∂sterir.

### 1. PostgreSQL'e Baƒülanma Y√∂ntemleri

#### A. Docker Container √úzerinden:
```bash
# PostgreSQL container'ƒ±na baƒülan:
docker exec -it nautilus-postgres psql -U trading_user -d nautilus_trading

# Veya .env dosyasƒ±ndaki deƒüi≈ükenlerle:
docker exec -it nautilus-postgres psql -U ${POSTGRES_USERNAME} -d ${POSTGRES_DATABASE}
```

#### B. Host'tan Baƒülanma:
```bash
# psql client kullanarak (port 5433'ten):
psql -h localhost -p 5433 -U trading_user -d nautilus_trading

# ≈ûifre: .env dosyasƒ±ndaki POSTGRES_PASSWORD
```

#### C. pgAdmin veya DBeaver ile GUI:
- Host: localhost
- Port: 5433
- Database: nautilus_trading
- Username: trading_user
- Password: .env dosyasƒ±ndaki deƒüer

### 2. Nautilus Trader Database Schema

#### Temel Tablolar:
```sql
-- T√ºm tablolarƒ± listele:
\dt

-- Tablo yapƒ±sƒ±nƒ± incele:
\d table_name

-- Yaygƒ±n tablolar:
\d bars            -- OHLCV bar data
\d ticks           -- Tick data (trades)
\d quotes          -- Quote data (bid/ask)
\d orders          -- Order history
\d trades          -- Executed trades
\d positions       -- Position history
\d accounts        -- Account states
\d instruments     -- Instrument definitions
```

### 3. Historical Data Sorgularƒ±

#### A. Bar Data (OHLCV) Sorgularƒ±:
```sql
-- Son 100 BTCUSDT 1-dakika barlarƒ±:
SELECT 
    ts_event,
    open,
    high,
    low,
    close,
    volume
FROM bars 
WHERE bar_type LIKE '%BTCUSDT%1-MINUTE%'
ORDER BY ts_event DESC 
LIMIT 100;

-- Belirli tarih aralƒ±ƒüƒ±ndaki barlar:
SELECT 
    ts_event,
    open,
    high,
    low,
    close,
    volume
FROM bars 
WHERE bar_type LIKE '%BTCUSDT%1-MINUTE%'
  AND ts_event >= '2025-06-15 00:00:00'
  AND ts_event <= '2025-06-16 23:59:59'
ORDER BY ts_event ASC;

-- G√ºnl√ºk OHLCV √∂zeti:
SELECT 
    DATE(ts_event) as date,
    MIN(open) as day_open,
    MAX(high) as day_high,
    MIN(low) as day_low,
    MAX(close) as day_close,
    SUM(volume) as total_volume
FROM bars 
WHERE bar_type LIKE '%BTCUSDT%1-MINUTE%'
GROUP BY DATE(ts_event)
ORDER BY date DESC;
```

#### B. Tick Data Sorgularƒ±:
```sql
-- Son trade tick'leri:
SELECT 
    ts_event,
    price,
    size,
    aggressor_side,
    trade_id
FROM ticks 
WHERE instrument_id = 'BTCUSDT.BINANCE'
  AND tick_type = 'TRADE'
ORDER BY ts_event DESC 
LIMIT 50;

-- Belirli fiyat aralƒ±ƒüƒ±ndaki trade'ler:
SELECT 
    ts_event,
    price,
    size,
    aggressor_side
FROM ticks 
WHERE instrument_id = 'BTCUSDT.BINANCE'
  AND tick_type = 'TRADE'
  AND price BETWEEN 100000 AND 110000
ORDER BY ts_event DESC;

-- Saatlik trade volume analizi:
SELECT 
    DATE_TRUNC('hour', ts_event) as hour,
    COUNT(*) as trade_count,
    SUM(size) as total_volume,
    AVG(price) as avg_price,
    MIN(price) as min_price,
    MAX(price) as max_price
FROM ticks 
WHERE instrument_id = 'BTCUSDT.BINANCE'
  AND tick_type = 'TRADE'
GROUP BY DATE_TRUNC('hour', ts_event)
ORDER BY hour DESC;
```

#### C. Quote Data Sorgularƒ±:
```sql
-- Son bid/ask quote'larƒ±:
SELECT 
    ts_event,
    bid_price,
    ask_price,
    bid_size,
    ask_size,
    (ask_price - bid_price) as spread
FROM ticks 
WHERE instrument_id = 'BTCUSDT.BINANCE'
  AND tick_type = 'QUOTE'
ORDER BY ts_event DESC 
LIMIT 50;

-- Spread analizi:
SELECT 
    DATE_TRUNC('minute', ts_event) as minute,
    AVG(ask_price - bid_price) as avg_spread,
    MIN(ask_price - bid_price) as min_spread,
    MAX(ask_price - bid_price) as max_spread
FROM ticks 
WHERE instrument_id = 'BTCUSDT.BINANCE'
  AND tick_type = 'QUOTE'
GROUP BY DATE_TRUNC('minute', ts_event)
ORDER BY minute DESC;
```

#### D. Trading Performance Sorgularƒ±:
```sql
-- Executed orders:
SELECT 
    ts_event,
    order_id,
    instrument_id,
    order_side,
    order_type,
    quantity,
    price,
    status
FROM orders 
WHERE trader_id = 'SANDBOX-TRADER-001'
ORDER BY ts_event DESC;

-- Position history:
SELECT 
    ts_event,
    instrument_id,
    position_side,
    quantity,
    avg_px_open,
    avg_px_close,
    unrealized_pnl,
    realized_pnl
FROM positions 
WHERE trader_id = 'SANDBOX-TRADER-001'
ORDER BY ts_event DESC;

-- Trading g√ºnl√ºk P&L:
SELECT 
    DATE(ts_event) as date,
    SUM(realized_pnl) as daily_pnl,
    COUNT(*) as trade_count
FROM positions 
WHERE trader_id = 'SANDBOX-TRADER-001'
  AND realized_pnl != 0
GROUP BY DATE(ts_event)
ORDER BY date DESC;
```

### 4. Python'dan Historical Data Eri≈üimi

#### A. Direct PostgreSQL Connection:
```python
import psql2
import pandas as pd
from decimal import Decimal

# Connection string (.env'den deƒüerleri al)
conn_string = f"postgresql://{username}:{password}@{host}:{port}/{database}"

# DataFrame olarak data √ßek:
def get_historical_bars(symbol, start_date, end_date):
    query = """
    SELECT 
        ts_event,
        open,
        high,
        low,
        close,
        volume
    FROM bars 
    WHERE bar_type LIKE %s
      AND ts_event >= %s
      AND ts_event <= %s
    ORDER BY ts_event ASC
    """
    
    with psycopg2.connect(conn_string) as conn:
        df = pd.read_sql_query(
            query, 
            conn, 
            params=[f'%{symbol}%1-MINUTE%', start_date, end_date]
        )
    
    return df

# Kullanƒ±m:
df = get_historical_bars('BTCUSDT', '2025-06-15', '2025-06-16')
print(df.head())
```

#### B. Nautilus Trader Data Client Kullanarak:
```python
from nautilus_trader.core.datetime import dt_to_unix_nanos
from nautilus_trader.model.identifiers import InstrumentId
from nautilus_trader.model.data import BarType

# Data client'tan historical data √ßek:
def get_nautilus_historical_data():
    # Bar type tanƒ±mla
    instrument_id = InstrumentId.from_str("BTCUSDT.BINANCE")
    bar_type = BarType.from_str("BTCUSDT.BINANCE-1-MINUTE-LAST-INTERNAL")
    
    # Cache'den data √ßek
    bars = cache.bars(bar_type)
    
    # Veya database'den direkt √ßek
    bars = cache.load_bars(bar_type)
    
    return bars

# DataFrame'e √ßevir:
def bars_to_dataframe(bars):
    data = []
    for bar in bars:
        data.append({
            'timestamp': bar.ts_event,
            'open': float(bar.open),
            'high': float(bar.high),
            'low': float(bar.low),
            'close': float(bar.close),
            'volume': float(bar.volume)
        })
    
    df = pd.DataFrame(data)
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ns')
    return df
```

### 5. Useful Analysis Queries

#### A. Technical Analysis Hazƒ±rlƒ±ƒüƒ±:
```sql
-- Moving averages i√ßin data:
SELECT 
    ts_event,
    close,
    AVG(close) OVER (
        ORDER BY ts_event 
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    ) as ma_10,
    AVG(close) OVER (
        ORDER BY ts_event 
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    ) as ma_20
FROM bars 
WHERE bar_type LIKE '%BTCUSDT%1-MINUTE%'
ORDER BY ts_event DESC;

-- Volatility analysis:
SELECT 
    DATE(ts_event) as date,
    AVG(high - low) as avg_range,
    STDDEV(close) as price_volatility,
    (MAX(high) - MIN(low)) / AVG(close) * 100 as daily_range_pct
FROM bars 
WHERE bar_type LIKE '%BTCUSDT%1-MINUTE%'
GROUP BY DATE(ts_event)
ORDER BY date DESC;
```

#### B. Trading Pattern Analysis:
```sql
-- Saatlik trading pattern:
SELECT 
    EXTRACT(hour from ts_event) as hour,
    AVG(volume) as avg_volume,
    COUNT(*) as bar_count,
    AVG(high - low) as avg_range
FROM bars 
WHERE bar_type LIKE '%BTCUSDT%1-MINUTE%'
GROUP BY EXTRACT(hour from ts_event)
ORDER BY hour;

-- Volume spike detection:
SELECT 
    ts_event,
    volume,
    close,
    volume / AVG(volume) OVER (
        ORDER BY ts_event 
        ROWS BETWEEN 20 PRECEDING AND 1 PRECEDING
    ) as volume_ratio
FROM bars 
WHERE bar_type LIKE '%BTCUSDT%1-MINUTE%'
  AND volume > 0
ORDER BY ts_event DESC;
```

### 6. Data Export

#### A. CSV Export:
```sql
-- CSV dosyasƒ±na export:
\copy (SELECT ts_event, open, high, low, close, volume FROM bars WHERE bar_type LIKE '%BTCUSDT%1-MINUTE%' ORDER BY ts_event) TO '/tmp/btcusdt_data.csv' WITH CSV HEADER;
```

#### B. Python ile Export:
```python
# DataFrame'i CSV'ye kaydet:
df.to_csv('historical_data.csv', index=False)

# Excel'e kaydet:
df.to_excel('historical_data.xlsx', index=False)

# Parquet format (b√ºy√ºk data i√ßin):
df.to_parquet('historical_data.parquet')
```

### 7. Performance Optimization

#### A. Index'ler:
```sql
-- Performans i√ßin index'ler:
CREATE INDEX IF NOT EXISTS idx_bars_instrument_time 
ON bars(instrument_id, ts_event);

CREATE INDEX IF NOT EXISTS idx_ticks_instrument_time 
ON ticks(instrument_id, ts_event);

-- Query performance check:
EXPLAIN ANALYZE SELECT * FROM bars WHERE bar_type LIKE '%BTCUSDT%' ORDER BY ts_event DESC LIMIT 100;
```

#### B. Data Retention:
```sql
-- Eski data temizliƒüi (dikkatli kullan!):
DELETE FROM bars WHERE ts_event < NOW() - INTERVAL '30 days';
DELETE FROM ticks WHERE ts_event < NOW() - INTERVAL '7 days';
```

### 8. Monitoring & Maintenance

```sql
-- Database size:
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Row counts:
SELECT 
    tablename,
    n_tup_ins as inserts,
    n_tup_upd as updates,
    n_tup_del as deletes
FROM pg_stat_user_tables 
WHERE schemaname = 'public';
```

---

## üí° ƒ∞pu√ßlarƒ±:

1. **B√ºy√ºk sorgular i√ßin**: LIMIT kullanƒ±n ve pagination yapƒ±n
2. **Performans i√ßin**: Uygun index'leri kullanƒ±n  
3. **Memory kullanƒ±mƒ±**: B√ºy√ºk resultset'ler i√ßin streaming kullanƒ±n
4. **Backup**: √ñnemli datalarƒ± d√ºzenli olarak yedekleyin
5. **Monitoring**: Query performance'ƒ±nƒ± takip edin

## üîß Troubleshooting:

- Connection error: `.env` dosyasƒ±ndaki credentials'larƒ± kontrol edin
- Slow queries: `EXPLAIN ANALYZE` ile query plan'ƒ±nƒ± inceleyin
- Memory issues: `work_mem` PostgreSQL parametresini artƒ±rƒ±n
- Lock issues: Uzun s√ºreli transaction'larƒ± ka√ßƒ±nƒ±n
